# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1316oNb4E5TpQDAj3e9DdMTr1yeQzg9u7
"""

from tqdm.auto import tqdm
import requests
from bs4 import BeautifulSoup

urls = ["https://www.siphhospital.com/th/medical-services/find-doctor"] + [
    f"https://www.siphhospital.com/th/medical-services/find-doctor?page={i}"
    for i in range(2, 71)
]

soups = []
for url in urls:
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
    else:
        print(url)
    soups.append(soup)

def get_doctor_details(doctor_soup):
    name = doctor_soup.find('div', class_='card-text-name-doctor').get_text(strip=True)
    image_src = doctor_soup.find('img', class_='circular--square')['src']
    url = doctor_soup.find('a', class_='card-btn-view-data-doctor')['href']
    try:
        tablecheck = doctor_soup.find('ul', class_='text-table-day').get_text()
        tablecheck = " ".join(tablecheck.strip().split())
    except:
        tablecheck = ""
    return {
        "name": name,
        "image_src": image_src,
        "url": url,
        "table_check": tablecheck,
    }

def get_profile_details(doctor_url):
    response = requests.get(doctor_url)
    details_soup = BeautifulSoup(response.text, 'html.parser')
    try:
        qualification = details_soup.find("div", class_="layout-column-one layout-column-editable").get_text(strip=True)
    except:
        qualification = ""
    try:
        expertise = details_soup.find("div", class_="doctor-qualification-content").get_text(strip=True)
    except:
        expertise = ""
    return qualification, expertise

doctor_details = []
for soup in tqdm(soups):
    divs = soup.find_all("div", class_='box-bg-gray text-center')
    for div in divs:
        doctor_detail = get_doctor_details(div)
        qual, expertise = get_profile_details(doctor_detail["url"])
        doctor_detail["qualification"] = qual
        doctor_detail["expertise"] = expertise
        doctor_details.append(doctor_detail)

import json
with open('siriraj_doctor_details.jsonl', 'w', encoding='utf-8') as jsonl_file:
    for i in doctor_details:
        jsonl_file.write(json.dumps(i, ensure_ascii=False) + '\n')

pip install llama-index
pip install langchain
pip install openai
pip install streamlit
import openai
openai.api_key = "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"

from llama_index.llms.vertex import Vertex
from google.oauth2 import service_account

import streamlit as st
from llama_index import (
    KeywordTableIndex,
    SimpleDirectoryReader,
    ServiceContext,
)
from llama_index import VectorStoreIndex,download_loader
from llama_index.output_parsers import LangchainOutputParser
from llama_index.llms import OpenAI
from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from pathlib import Path

st.set_page_config(page_title="Chatbot for doctor appointment", page_icon="ðŸ¦™", layout="centered", initial_sidebar_state="auto", menu_items=None)
st.title("Chatbot for doctor appointment")
st.info("Check out the full tutorial to build this app in our [blog post](https://blog.streamlit.io/build-a-chatbot-with-custom-data-sources-powered-by-llamaindex/)", icon="ðŸ“ƒ")

if "messages" not in st.session_state.keys(): # Initialize the chat messages history
    st.session_state.messages = [
        {"role": "assistant", "content": "Ask me a question about doctor appointment"}
    ]
@st.cache_resource(show_spinner=False)
def load_data():
    with st.spinner(text="Loading and indexing the Streamlit docs â€“ hang tight! This should take 1-2 minutes."):
        JSONReader = download_loader("JSONReader")
        loader = JSONReader()
        service_context = ServiceContext.from_defaults(llm=OpenAI(model="gpt-3.5-turbo", temperature=0.5, system_prompt=" Your job is to answer the questions in Thai. Keep your answers based on facts â€“ do not hallucinate features."))
        document = loader.load_data(Path('/content/siriraj_doctor_details.jsonl'), is_jsonl=True)
        index = VectorStoreIndex.from_documents(document,service_context=service_context)

        return index

index = load_data()

if "chat_engine" not in st.session_state.keys(): # Initialize the chat engine
        st.session_state.chat_engine = index.as_chat_engine(chat_mode="condense_question", verbose=True)

if prompt := st.chat_input("Your question"): # Prompt for user input and save to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

for message in st.session_state.messages: # Display the prior chat messages
    with st.chat_message(message["role"]):
        st.write(message["content"])

# If last message is not from assistant, generate a new response
if st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = st.session_state.chat_engine.chat(prompt)
            st.write(response.response)
            message = {"role": "assistant", "content": response.response}
            st.session_state.messages.append(message) # Add response to message history
